#include 
#include 

__global__ void kernel(int *data, int N) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < N) {
        data[idx] = data[idx] * 2; // Double each element
    }
}

int main() {
    const int N = 1024;
    int *data;
    
    // Allocate unified memory accessible from both CPU and GPU
    cudaMallocManaged(&data, N * sizeof(int));
    
    // Initialize data on the CPU
    for (int i = 0; i < N; i++) {
        data[i] = i;
    }
    
    // Launch kernel to process data on the GPU
    kernel<<<(N + 255) / 256, 256>>>(data, N);
    
    // Synchronize to ensure kernel completion
    cudaDeviceSynchronize();
    
    // Verify results on the CPU
    for (int i = 0; i < N; i++) {
        if (data[i] != i * 2) {
            std::cerr << "Error at index " << i << std::endl;
            break;
        }
    }
    
    // Free unified memory
    cudaFree(data);
    
    std::cout << "Unified memory access successful!" << std::endl;
    return 0;
}