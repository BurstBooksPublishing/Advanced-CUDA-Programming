#include 
#include 

#define N 1024  // Number of elements in the array
#define BLOCK_SIZE 32  // Threads per block

// Kernel to perform a simple computation with pipeline optimization
__global__ void pipelineOptimizedKernel(float* input, float* output, int n) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < n) {
        // Stage 1: Load data into shared memory
        __shared__ float sharedData[BLOCK_SIZE];
        sharedData[threadIdx.x] = input[idx];
        __syncthreads();

        // Stage 2: Perform computation
        float result = sharedData[threadIdx.x] * 2.0f;
        __syncthreads();

        // Stage 3: Store result back to global memory
        output[idx] = result;
    }
}

int main() {
    float *h_input, *h_output;
    float *d_input, *d_output;

    // Allocate host memory
    h_input = (float*)malloc(N * sizeof(float));
    h_output = (float*)malloc(N * sizeof(float));

    // Initialize host input
    for (int i = 0; i < N; i++) {
        h_input[i] = (float)i;
    }

    // Allocate device memory
    cudaMalloc((void**)&d_input, N * sizeof(float));
    cudaMalloc((void**)&d_output, N * sizeof(float));

    // Copy input data to device
    cudaMemcpy(d_input, h_input, N * sizeof(float), cudaMemcpyHostToDevice);

    // Launch kernel with pipeline optimization
    pipelineOptimizedKernel<<<(N + BLOCK_SIZE - 1) / BLOCK_SIZE, BLOCK_SIZE>>>(d_input, d_output, N);

    // Copy result back to host
    cudaMemcpy(h_output, d_output, N * sizeof(float), cudaMemcpyDeviceToHost);

    // Free device memory
    cudaFree(d_input);
    cudaFree(d_output);

    // Free host memory
    free(h_input);
    free(h_output);

    return 0;
}