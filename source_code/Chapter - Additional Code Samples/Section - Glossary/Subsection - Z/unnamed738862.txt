#include 
#include 
#include 

#define CHECK_CUDA(call) \
    do { \
        cudaError_t err = call; \
        if (err != cudaSuccess) { \
            std::cerr << "CUDA error: " << cudaGetErrorString(err) \
                      << " at " << __FILE__ << ":" << __LINE__ << std::endl; \
            exit(EXIT_FAILURE); \
        } \
    } while (0)

#define CHECK_CUBLAS(call) \
    do { \
        cublasStatus_t err = call; \
        if (err != CUBLAS_STATUS_SUCCESS) { \
            std::cerr << "CUBLAS error: " << err \
                      << " at " << __FILE__ << ":" << __LINE__ << std::endl; \
            exit(EXIT_FAILURE); \
        } \
    } while (0)

int main() {
    const int M = 1024, N = 1024, K = 1024; // Matrix dimensions
    const int size_A = M * K * sizeof(__half); // Size of matrix A in bytes
    const int size_B = K * N * sizeof(__half); // Size of matrix B in bytes
    const int size_C = M * N * sizeof(__half); // Size of matrix C in bytes

    __half *h_A = (__half *)malloc(size_A); // Host matrix A
    __half *h_B = (__half *)malloc(size_B); // Host matrix B
    __half *h_C = (__half *)malloc(size_C); // Host matrix C

    // Initialize matrices A and B with random values
    for (int i = 0; i < M * K; i++) h_A[i] = __float2half(static_cast(rand()) / RAND_MAX);
    for (int i = 0; i < K * N; i++) h_B[i] = __float2half(static_cast(rand()) / RAND_MAX);

    __half *d_A, *d_B, *d_C; // Device matrices
    CHECK_CUDA(cudaMalloc(&d_A, size_A));
    CHECK_CUDA(cudaMalloc(&d_B, size_B));
    CHECK_CUDA(cudaMalloc(&d_C, size_C));

    // Copy matrices A and B to device
    CHECK_CUDA(cudaMemcpy(d_A, h_A, size_A, cudaMemcpyHostToDevice));
    CHECK_CUDA(cudaMemcpy(d_B, h_B, size_B, cudaMemcpyHostToDevice));

    cublasHandle_t handle;
    CHECK_CUBLAS(cublasCreate(&handle));

    // Set the math mode to use Tensor Cores
    CHECK_CUBLAS(cublasSetMathMode(handle, CUBLAS_TENSOR_OP_MATH));

    const __half alpha = __float2half(1.0f); // Scaling factor for A*B
    const __half beta = __float2half(0.0f);  // Scaling factor for C

    // Perform matrix multiplication using Tensor Cores
    CHECK_CUBLAS(cublasGemmEx(handle, CUBLAS_OP_N, CUBLAS_OP_N, 
                              M, N, K, &alpha, 
                              d_A, CUDA_R_16F, M, 
                              d_B, CUDA_R_16F, K, 
                              &beta, 
                              d_C, CUDA_R_16F, M, 
                              CUDA_R_16F, CUBLAS_GEMM_DEFAULT_TENSOR_OP));

    // Copy result matrix C back to host
    CHECK_CUDA(cudaMemcpy(h_C, d_C, size_C, cudaMemcpyDeviceToHost));

    // Cleanup
    CHECK_CUBLAS(cublasDestroy(handle));
    CHECK_CUDA(cudaFree(d_A));
    CHECK_CUDA(cudaFree(d_B));
    CHECK_CUDA(cudaFree(d_C));
    free(h_A);
    free(h_B);
    free(h_C);

    return 0;
}