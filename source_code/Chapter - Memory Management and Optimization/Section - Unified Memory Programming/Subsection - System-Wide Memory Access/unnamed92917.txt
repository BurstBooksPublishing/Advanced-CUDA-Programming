// CUDA kernel to demonstrate system-wide memory access using Unified Memory
__global__ void systemWideMemoryAccess(float* data, int N) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < N) {
        // Perform a simple operation on the data
        data[idx] = data[idx] * 2.0f; // Example computation
    }
}

int main() {
    int N = 1 << 20; // Size of the data array
    float *data;
    
    // Allocate Unified Memory accessible from CPU and GPU
    cudaMallocManaged(&data, N * sizeof(float));
    
    // Initialize data on the host
    for (int i = 0; i < N; i++) {
        data[i] = static_cast(i);
    }
    
    // Launch the kernel with 256 threads per block
    int blockSize = 256;
    int numBlocks = (N + blockSize - 1) / blockSize;
    systemWideMemoryAccess<<>>(data, N);
    
    // Synchronize to ensure kernel execution is complete
    cudaDeviceSynchronize();
    
    // Free the Unified Memory
    cudaFree(data);
    
    return 0;
}