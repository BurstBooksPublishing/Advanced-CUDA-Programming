#include 
#include 

#define N 1024 * 1024

__global__ void kernel(float *d_out, float *d_in) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < N) {
        d_out[idx] = d_in[idx] * 2.0f; // Simple computation
    }
}

int main() {
    float *h_in, *h_out;
    float *d_in, *d_out;
    cudaStream_t stream1, stream2;

    // Allocate host memory
    h_in = (float *)malloc(N * sizeof(float));
    h_out = (float *)malloc(N * sizeof(float));

    // Allocate device memory
    cudaMalloc((void **)&d_in, N * sizeof(float));
    cudaMalloc((void **)&d_out, N * sizeof(float));

    // Create CUDA streams
    cudaStreamCreate(&stream1);
    cudaStreamCreate(&stream2);

    // Initialize host data
    for (int i = 0; i < N; i++) {
        h_in[i] = static_cast(i);
    }

    // Asynchronous memory transfers and kernel execution
    cudaMemcpyAsync(d_in, h_in, N/2 * sizeof(float), 
                    cudaMemcpyHostToDevice, stream1);
    cudaMemcpyAsync(d_in + N/2, h_in + N/2, N/2 * sizeof(float), 
                    cudaMemcpyHostToDevice, stream2);

    kernel<<<(N/2 + 255)/256, 256, 0, stream1>>>(d_out, d_in);
    kernel<<<(N/2 + 255)/256, 256, 0, stream2>>>(d_out + N/2, d_in + N/2);

    cudaMemcpyAsync(h_out, d_out, N/2 * sizeof(float), 
                    cudaMemcpyDeviceToHost, stream1);
    cudaMemcpyAsync(h_out + N/2, d_out + N/2, N/2 * sizeof(float), 
                    cudaMemcpyDeviceToHost, stream2);

    // Synchronize streams
    cudaStreamSynchronize(stream1);
    cudaStreamSynchronize(stream2);

    // Cleanup
    cudaFree(d_in);
    cudaFree(d_out);
    free(h_in);
    free(h_out);
    cudaStreamDestroy(stream1);
    cudaStreamDestroy(stream2);

    return 0;
}